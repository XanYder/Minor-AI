{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49fadad7",
   "metadata": {},
   "source": [
    "# Imports & test data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0f289076",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import classification_report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec55b819",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Website for the dataset:\n",
    "# https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/data?select=icml_face_data.csv\n",
    "\n",
    "CLASS_NAMES = [\"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Sad\", \"Surprise\", \"Neutral\"]\n",
    "CLASS_NAMES_WITHOUT_DISGUST = [\"Angry\", \"Fear\", \"Happy\", \"Sad\", \"Surprise\", \"Neutral\"]\n",
    "FILE_NAME = \"train.csv\" # Insert file name\n",
    "WHITE_IMAGES = [6458,  7629, 10423, 11286, 13148, 13402, 13988, 15894, 22198, 22927, 28601, 59]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "804279ae",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path = [\"data\"] # Insert data file path\n",
    "file_path = os.sep.join(data_path + [FILE_NAME])\n",
    "data = pd.read_csv(file_path)\n",
    "data = data.drop(index=WHITE_IMAGES, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b6fa6b5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_exclude_disgust = data[data['emotion'] != 1] # Drops the emotion Disgust\n",
    "data_exclude_disgust = data_exclude_disgust.replace({\n",
    "    2 : 1,\n",
    "    3 : 2,\n",
    "    4 : 3,\n",
    "    5 : 4,\n",
    "    6 : 5\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e0ec892",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_X_y(data):\n",
    "    # Split data into X & y\n",
    "    X = data.drop('emotion', axis='columns')\n",
    "    y = data['emotion']\n",
    "\n",
    "    # Reshapes X into 3D array\n",
    "    X = [pixels.split(\" \") for pixels in data[\"pixels\"]]\n",
    "    X = np.array(X)\n",
    "    X = X.astype(\"int32\")\n",
    "    X = np.array([image.reshape(48, 48) for image in X])\n",
    "    X = X/255.0\n",
    "    X = X.reshape(len(X), 48, 48, 1)\n",
    "    \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5419c07",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X,y = data_X_y(data_exclude_disgust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6b99665",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28709</th>\n",
       "      <td>0</td>\n",
       "      <td>254 254 254 254 254 249 255 160 2 58 53 70 77 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28710</th>\n",
       "      <td>1</td>\n",
       "      <td>156 184 198 202 204 207 210 212 213 214 215 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28711</th>\n",
       "      <td>4</td>\n",
       "      <td>69 118 61 60 96 121 103 87 103 88 70 90 115 12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28712</th>\n",
       "      <td>6</td>\n",
       "      <td>205 203 236 157 83 158 120 116 94 86 155 180 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28713</th>\n",
       "      <td>3</td>\n",
       "      <td>87 79 74 66 74 96 77 80 80 84 83 89 102 91 84 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       emotion                                             pixels\n",
       "28709        0  254 254 254 254 254 249 255 160 2 58 53 70 77 ...\n",
       "28710        1  156 184 198 202 204 207 210 212 213 214 215 21...\n",
       "28711        4  69 118 61 60 96 121 103 87 103 88 70 90 115 12...\n",
       "28712        6  205 203 236 157 83 158 120 116 94 86 155 180 2...\n",
       "28713        3  87 79 74 66 74 96 77 80 80 84 83 89 102 91 84 ..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = os.sep.join(data_path + ['emotions.csv'])\n",
    "data_test = pd.read_csv(file_path)\n",
    "test = [\"PrivateTest\", \"PublicTest\"]\n",
    "data_test = data_test[data_test['Usage'].isin(test) ]\n",
    "\n",
    "# If icml_face_data.csv is used\n",
    "data_test.drop('Usage', axis=1, inplace=True)\n",
    "\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d50a1be3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7178, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25e4b1e0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7067, 2), array([0, 3, 5, 2, 1, 4]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = data_test[data_test['emotion'] != 1] # Drops the emotion Disgust\n",
    "data_test = data_test.replace({\n",
    "    2 : 1,\n",
    "    3 : 2,\n",
    "    4 : 3,\n",
    "    5 : 4,\n",
    "    6 : 5\n",
    "})\n",
    "data_test.shape, data_test.emotion.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f13bd70",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reshape_X(X):\n",
    "    num_training = X.shape[0]\n",
    "    mask = list(range(num_training))\n",
    "    X_reshape = X[mask]\n",
    "\n",
    "    # Reshape the image data into rows\n",
    "    X_reshape = np.reshape(X, (X.shape[0], -1))\n",
    "    \n",
    "    return X_reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46fd55dd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test, y_test = data_X_y(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e25e29d3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test = reshape_X(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8414b6",
   "metadata": {},
   "source": [
    "# CNN Model testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fec73c",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Only the 3 best CNN models will be used for the testing. Otherwise there would be too much models to test if we thoroughly tested the worse models since these 3 models are the best combinations that came out of the previous models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49bcda6",
   "metadata": {},
   "source": [
    "### More imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98744a62",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from resizeimage import resizeimage\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae144083",
   "metadata": {},
   "source": [
    "### Model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d1ad055",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CNNModelx1 = tf.keras.models.load_model(\"models/CNNmodelx-1\")\n",
    "# CNNModelx2 = tf.keras.models.load_model(\"models/CNNmodelx-2\")\n",
    "# CNNModelx3 = tf.keras.models.load_model(\"models/CNNmodelx-3\")\n",
    "# CNNModelx4 = tf.keras.models.load_model(\"models/CNNmodelx-4\")\n",
    "# CNNModelx5 = tf.keras.models.load_model(\"models/CNNmodelx-5\")\n",
    "# CNNModelx6 = tf.keras.models.load_model(\"models/CNNmodelx-6\")\n",
    "# CNNModelx7 = tf.keras.models.load_model(\"models/CNNmodelx-7\")\n",
    "# CNNModelx8 = tf.keras.models.load_model(\"models/CNNmodelx-8\")\n",
    "# CNNModelx9 = tf.keras.models.load_model(\"models/CNNmodelx-9\")\n",
    "\n",
    "CNNModel3 = tf.keras.models.load_model(\"models/CNNmodel3\")\n",
    "CNNModel4 = tf.keras.models.load_model(\"models/CNNmodel4\")\n",
    "CNNModel5 = tf.keras.models.load_model(\"models/CNNmodel5\")\n",
    "# CNNModel6 = tf.keras.models.load_model(\"models/CNNmodel6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c952be5e",
   "metadata": {},
   "source": [
    "### Model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04a618e5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [04:26<00:00, 88.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 50min 10s, sys: 1min 13s, total: 51min 23s\n",
      "Wall time: 4min 26s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# models = {0: {\"model\": CNNModelx1, \"predictions\": None}, 1: {\"model\": CNNModelx2, \"predictions\": None}, \n",
    "#           2: {\"model\": CNNModelx3, \"predictions\": None}, 3: {\"model\": CNNModelx4, \"predictions\": None}, \n",
    "#           4: {\"model\": CNNModelx5, \"predictions\": None}, 5: {\"model\": CNNModelx6, \"predictions\": None}, \n",
    "#           6: {\"model\": CNNModelx7, \"predictions\": None}, 7: {\"model\": CNNModelx8, \"predictions\": None}, \n",
    "#           8: {\"model\": CNNModelx9, \"predictions\": None}, 9: {\"model\": CNNModel3, \"predictions\": None}, \n",
    "#           10: {\"model\": CNNModel4, \"predictions\": None}, 11: {\"model\": CNNModel5, \"predictions\": None}\n",
    "#          }\n",
    "\n",
    "models = {0: {\"model\": CNNModel3, \"predictions\": None}, \n",
    "          1: {\"model\": CNNModel4, \"predictions\": None}, \n",
    "          2: {\"model\": CNNModel5, \"predictions\": None}\n",
    "         }\n",
    "\n",
    "X_test_resh = X_test.reshape(len(X_test), 48, 48, 1)\n",
    "\n",
    "for key in tqdm(models.keys()):\n",
    "    models[key][\"predictions\"] = models[key][\"model\"].predict(X_test_resh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8e0b796",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 53.79it/s]\n"
     ]
    }
   ],
   "source": [
    "for key in tqdm(models.keys()):\n",
    "    for x in range(len(models[key][\"predictions\"])):\n",
    "        models[key][\"predictions\"][x] = np.argmax(models[key][\"predictions\"][x])\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0b718a70",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 44938.97it/s]\n"
     ]
    }
   ],
   "source": [
    "for key in tqdm(models.keys()):\n",
    "     models[key][\"predictions\"] = models[key][\"predictions\"][:, :1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536c6d8b",
   "metadata": {},
   "source": [
    "# Model results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c562920",
   "metadata": {},
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e3c290",
   "metadata": {},
   "source": [
    "##### This is one the three CNN models that peformed really great on the model evaluation. As you can see below it has a test accuracy of ~93%. This means from all the test samples it correctly classified ~93% of them. But to see whether it really performs as great as we want we also will have a look at the precision, recall and F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "666df29b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221/221 [==============================] - 81s 366ms/step - loss: 0.2810 - accuracy: 0.9273\n",
      "\n",
      "The accuracy of the first model is: 0.9272676110267639%\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nThe accuracy of the first model is: {CNNModel3.evaluate(X_test_resh, y_test)[1]}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663dd5da",
   "metadata": {},
   "source": [
    "##### The structure of the model can be seen below which has been trained on the random oversampled data. With Adam as the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d6ff7cfb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 48, 48, 64)        128       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 48, 48, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 48, 48, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 48, 48, 128)       512       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 48, 48, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 48, 48, 256)       819456    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 48, 48, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 24, 24, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 24, 24, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 147456)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               18874496  \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 19,804,806\n",
      "Trainable params: 19,803,654\n",
      "Non-trainable params: 1,152\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "CNNModel3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dee540",
   "metadata": {},
   "source": [
    "##### Here below we can see the precision, recall and F1 score of the model. The highest precision score is on the happy emotion which is 97%. So this tells us what proportion of happy classifications was actually correct. But the recall for the happy emotion is one of the lowest which means that of all the actual happy faces it only correctly identified 93% of them correctly. A reason why the recall is lower could be that since this model was trained on random oversampled data, the happy emotion had the most emotions meaning that the happy emotions didn't get oversampled. Which resulted in the model not being able to learn the invariants of the happy emotion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73768e0f",
   "metadata": {},
   "source": [
    "##### The F1 score for each of the emotions are higher than 90% which is really high. This gives us a good comprehension that this model its performance is really high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aae1cee0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Angry       0.92      0.93      0.93       958\n",
      "        Fear       0.91      0.91      0.91      1024\n",
      "       Happy       0.97      0.93      0.95      1774\n",
      "         Sad       0.90      0.92      0.91      1247\n",
      "    Surprise       0.96      0.97      0.97       831\n",
      "     Neutral       0.90      0.92      0.91      1233\n",
      "\n",
      "    accuracy                           0.93      7067\n",
      "   macro avg       0.93      0.93      0.93      7067\n",
      "weighted avg       0.93      0.93      0.93      7067\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, models[0][\"predictions\"], target_names = CLASS_NAMES_WITHOUT_DISGUST))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a715861",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb327a2",
   "metadata": {},
   "source": [
    "##### This model was trained with the same model architecture as the first model. But instead of random oversampled we used smothe on this model to see whether this model would perform better or worse with a more complicated oversampling method. This has the same accuracy as the first model (off by 0.001%). But does this mean the precision, recall and F1 score are also the same? That is what we will be looking into."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fd65d5e2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221/221 [==============================] - 81s 367ms/step - loss: 0.3736 - accuracy: 0.9259\n",
      "\n",
      "The accuracy of the second model is: 0.9258525371551514%\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nThe accuracy of the second model is: {CNNModel4.evaluate(X_test_resh, y_test)[1]}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2b15dc",
   "metadata": {},
   "source": [
    "##### Like with the last model the surpise and happy emotion classifications are higher than the others. But in general compared with the previous model, this model has the same F1 score for happy. Even though the precision of the first model for happy was 0.97 and recall 0.93. And for this model the precision is 0.95 and the recall 0.95 which proves that the F1 score is basically the ratio between precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aacec303",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Angry       0.90      0.93      0.92       958\n",
      "        Fear       0.91      0.91      0.91      1024\n",
      "       Happy       0.95      0.95      0.95      1774\n",
      "         Sad       0.90      0.90      0.90      1247\n",
      "    Surprise       0.95      0.97      0.96       831\n",
      "     Neutral       0.94      0.90      0.92      1233\n",
      "\n",
      "    accuracy                           0.93      7067\n",
      "   macro avg       0.92      0.93      0.93      7067\n",
      "weighted avg       0.93      0.93      0.93      7067\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, models[1][\"predictions\"], target_names = CLASS_NAMES_WITHOUT_DISGUST))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b7b944",
   "metadata": {},
   "source": [
    "## Model 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ea4cf0",
   "metadata": {},
   "source": [
    "##### This model has been trained on the augmented data where the images have been horizontally flipped, rotated a bit and zoomed in and out. Using the augmented data the model will be able to better learn the invariants of the emotions. Looking at the test accuracy below the model has an accuracy of ~94% which is the highest scoring CNN model we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7ffad430",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221/221 [==============================] - 84s 381ms/step - loss: 0.3096 - accuracy: 0.9377\n",
      "\n",
      "The accuracy of the third model is: 0.9377387762069702%\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nThe accuracy of the third model is: {CNNModel5.evaluate(X_test_resh, y_test)[1]}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79020bd",
   "metadata": {},
   "source": [
    "##### The most noticable improvement of this model compared to the previous models is that this model has done better in classifying the fear emotion. This model its precision is 0.3% higher than the previous models. Which increased its F1 score to 0.93 which is the best one we got. Because fear has a resembles with surprise it was always lower than the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f338e607",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Angry       0.93      0.94      0.94       958\n",
      "        Fear       0.94      0.91      0.93      1024\n",
      "       Happy       0.97      0.94      0.95      1774\n",
      "         Sad       0.90      0.94      0.92      1247\n",
      "    Surprise       0.95      0.97      0.96       831\n",
      "     Neutral       0.93      0.92      0.93      1233\n",
      "\n",
      "    accuracy                           0.94      7067\n",
      "   macro avg       0.94      0.94      0.94      7067\n",
      "weighted avg       0.94      0.94      0.94      7067\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, models[2][\"predictions\"], target_names = CLASS_NAMES_WITHOUT_DISGUST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e2552915",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9d3015e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9160696  0.02763562 0.02149437 0.01535312 0.00307062 0.01637666]\n",
      " [0.00976562 0.90625    0.02636719 0.02539062 0.0078125  0.02441406]\n",
      " [0.00413956 0.00236546 0.9704317  0.01064459 0.00295683 0.00946186]\n",
      " [0.01877934 0.02425665 0.02973396 0.89514867 0.00391236 0.02816901]\n",
      " [0.0011919  0.02145411 0.00834327 0.00238379 0.96305125 0.00357569]\n",
      " [0.01669316 0.0127186  0.0317965  0.03338633 0.00158983 0.90381558]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(models[0][\"predictions\"], y_test, normalize = \"true\", labels = []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905e81b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
